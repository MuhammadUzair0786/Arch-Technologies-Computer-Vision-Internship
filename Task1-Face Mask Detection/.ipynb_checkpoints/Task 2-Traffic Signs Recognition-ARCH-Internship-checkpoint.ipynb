{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8613ac",
   "metadata": {},
   "source": [
    "# ARCH Technologies Internship - Task 2-Traffic Signs Recognition\n",
    "Using a dataset of traffic sign images, build a computer vision model to recognize\n",
    "and classify different traffic signs such as stop, yield, or speed limit signs.\n",
    "Preprocess the images, train a convolutional neural network (CNN), and evaluate its\n",
    "accuracy in correctly identifying the signs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e414a",
   "metadata": {},
   "source": [
    "# 1) Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74428c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c0cdb",
   "metadata": {},
   "source": [
    "# 2) Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53301868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "DATASET_DIR = r\"E:\\AI Projects\\Arch Technologies Internship Tasks\\Task1-Face Mask Detection\\data\"\n",
    "\n",
    "valid_ext = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_path = os.path.join(DATASET_DIR, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_file in os.listdir(class_path):\n",
    "        if not img_file.lower().endswith(valid_ext):\n",
    "            continue\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            if img.mode in ('P', 'LA', 'RGBA'):  # Palette or transparency modes\n",
    "                img = img.convert('RGB')\n",
    "                img.save(img_path)  # Overwrite with RGB version\n",
    "                print(f\"Converted {img_path} to RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4462d",
   "metadata": {},
   "source": [
    "# 3) Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=20,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "shear_range=0.1,\n",
    "zoom_range=0.1,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest',\n",
    "validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "DATASET_DIR,\n",
    "target_size=IMG_SIZE,\n",
    "batch_size=BATCH_SIZE,\n",
    "class_mode='binary',\n",
    "subset='training',\n",
    "seed=SEED\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "DATASET_DIR,\n",
    "target_size=IMG_SIZE,\n",
    "batch_size=BATCH_SIZE,\n",
    "class_mode='binary',\n",
    "subset='validation',\n",
    "seed=SEED\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save class indices mapping to a JSON so prediction cell can use it later\n",
    "class_indices = train_generator.class_indices\n",
    "inv_map = {v: k for k, v in class_indices.items()}\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(inv_map, f)\n",
    "\n",
    "\n",
    "print('\\nClass mapping (index -> label):', inv_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c54b5b3",
   "metadata": {},
   "source": [
    "# 4) Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    model = Sequential([\n",
    "        # First Convolutional Block\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e9ab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 57600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               7372928   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,400,641\n",
      "Trainable params: 7,400,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bbbb2",
   "metadata": {},
   "source": [
    "# 5) Callbacks and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1)\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "train_generator,\n",
    "epochs=EPOCHS,\n",
    "validation_data=val_generator,\n",
    "callbacks=[early, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d7257",
   "metadata": {},
   "source": [
    "# 7) Evaluate on validation set (best model saved as Traffic_signs_detector.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Traffic_signs_detector.h5')\n",
    "print(\"Model saved successfully!\")\n",
    "val_loss, val_acc = model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model directly — no need to \n",
    "best_model = model\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation loss: {val_loss:.4f} - Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c556545",
   "metadata": {},
   "source": [
    "# 7) Plot training history (loss & accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0152a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get number of epochs actually trained (in case EarlyStopping stopped it early)\n",
    "epochs_trained = len(history.history['loss'])\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "plt.title('Model Loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xticks(range(0, epochs_trained, max(1, epochs_trained//10)))\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "plt.title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xticks(range(0, epochs_trained, max(1, epochs_trained//10)))\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791c602",
   "metadata": {},
   "source": [
    "# 8) Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(val_generator)\n",
    "y_pred_classes = (y_pred >= 0.5).astype(int).ravel()\n",
    "y_true = val_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=inv_map.values(), yticklabels=inv_map.values())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=inv_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f91be",
   "metadata": {},
   "source": [
    "# 9) Show sample images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d73094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample_paths = random.sample(val_generator.filepaths, 5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for i, path in enumerate(sample_paths):\n",
    "    result = best_model.predict(np.expand_dims(np.array(Image.open(path).convert('RGB').resize(IMG_SIZE))/255.0, axis=0))[0][0]\n",
    "    pred_label = inv_map[1] if result >= 0.5 else inv_map[0]\n",
    "    plt.subplot(1,5,i+1)\n",
    "    img = Image.open(path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Pred: {pred_label}\\nConf: {result:.2f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82c710",
   "metadata": {},
   "source": [
    "# 10) Single image prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e6f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image(image_path, model_path='Face_mask_detector.h5', img_size=(128, 128), threshold=0.5, show_image=True):\n",
    "    \"\"\"Load model, prepare image, predict, and optionally show image with prediction.\"\"\"\n",
    "    try:\n",
    "        # Load model\n",
    "        from tensorflow.keras.models import load_model\n",
    "        model = load_model(model_path)\n",
    "        \n",
    "        # Load class mapping\n",
    "        import json\n",
    "        with open('class_indices.json', 'r') as f:\n",
    "            inv_map = json.load(f)\n",
    "        inv_map = {int(k): v for k, v in inv_map.items()}  # Convert keys to int\n",
    "\n",
    "        # Prepare image\n",
    "        import numpy as np\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_resized = img.resize(img_size)\n",
    "        arr = np.array(img_resized) / 255.0\n",
    "        arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "        # Predict\n",
    "        prob = model.predict(arr)[0][0]  # Sigmoid output\n",
    "        predicted_index = 1 if prob >= threshold else 0\n",
    "        predicted_label = inv_map[predicted_index]\n",
    "        confidence = float(prob) if predicted_index == 1 else float(1.0 - prob)\n",
    "\n",
    "        # Show image if requested\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(img)  # Show original image (not resized)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Prediction: {predicted_label}\\nConfidence: {confidence:.2f} (Raw: {prob:.4f})\", fontsize=12, fontweight='bold')\n",
    "            plt.show()\n",
    "\n",
    "        return {\n",
    "            'label': predicted_label,\n",
    "            'confidence': confidence,\n",
    "            'raw_score': float(prob)\n",
    "        }\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        return {\"error\": f\"File not found: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dea6d4",
   "metadata": {},
   "source": [
    "# 11) Test Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ca48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"E:\\AI Projects\\Arch Technologies Internship Tasks\\Task1-Face Mask Detection\\data\\with_mask\\mask_test.jpg\"\n",
    "\n",
    "result = predict_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0592f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = r\"E:\\AI Projects\\Arch Technologies Internship Tasks\\Task1-Face Mask Detection\\data\\with_mask\\mask_test.jpg\"\n",
    "\n",
    "result = predict_image(test_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
